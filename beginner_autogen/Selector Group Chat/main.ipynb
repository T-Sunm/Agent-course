{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebe64ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Sequence\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent, UserProxyAgent\n",
    "from autogen_agentchat.conditions import MaxMessageTermination, TextMentionTermination\n",
    "from autogen_agentchat.messages import BaseAgentEvent, BaseChatMessage\n",
    "from autogen_agentchat.teams import SelectorGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_core.models import ChatCompletionClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aaec75",
   "metadata": {},
   "source": [
    "## Define Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f943914",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"provider\": \"OpenAIChatCompletionClient\",\n",
    "    \"config\": {\n",
    "        \"model\": \"llama-3.2-3b-instruct\",\n",
    "        \"base_url\": \"http://127.0.0.1:1234/v1\",\n",
    "        \"api_key\": \"lm-studio\",\n",
    "        \"model_info\": {\n",
    "            \"name\": \"llama-3.2-3b-instruct\",\n",
    "            \"family\": \"openai\",\n",
    "            \"supports_tool_calling\": False,\n",
    "            \"supports_json_mode\": False,\n",
    "            \"structured_output\": True,\n",
    "            \"json_output\": True,\n",
    "            \"function_calling\": True,\n",
    "            \"vision\": False,\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "model_client = ChatCompletionClient.load_component(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6d2b3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This example uses mock tools instead of real APIs for demonstration purposes\n",
    "def search_web_tool(query: str) -> str:\n",
    "    if \"2006-2007\" in query:\n",
    "        return \"\"\"Here are the total points scored by Miami Heat players in the 2006-2007 season:\n",
    "        Udonis Haslem: 844 points\n",
    "        Dwayne Wade: 1397 points\n",
    "        James Posey: 550 points\n",
    "        ...\n",
    "        \"\"\"\n",
    "    elif \"2007-2008\" in query:\n",
    "        return \"The number of total rebounds for Dwayne Wade in the Miami Heat season 2007-2008 is 214.\"\n",
    "    elif \"2008-2009\" in query:\n",
    "        return \"The number of total rebounds for Dwayne Wade in the Miami Heat season 2008-2009 is 398.\"\n",
    "    return \"No data found.\"\n",
    "\n",
    "\n",
    "def percentage_change_tool(start: float, end: float) -> float:\n",
    "    return ((end - start) / start) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2def40eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "planning_agent = AssistantAgent(\n",
    "    \"PlanningAgent\",\n",
    "    description=\"An agent for planning tasks, this agent should be the first to engage when given a new task.\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"\"\"\n",
    "    You are a planning agent.\n",
    "    Your job is to break down complex tasks into smaller, manageable subtasks.\n",
    "    Your team members are:\n",
    "        WebSearchAgent: Searches for information\n",
    "        DataAnalystAgent: Performs calculations\n",
    "\n",
    "    You only plan and delegate tasks - you do not execute them yourself.\n",
    "\n",
    "    When assigning tasks, use this format:\n",
    "    1. <agent> : <task>\n",
    "\n",
    "    After all tasks are complete, summarize the findings and end with \"TERMINATE\".\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "web_search_agent = AssistantAgent(\n",
    "    \"WebSearchAgent\",\n",
    "    description=\"An agent for searching information on the web.\",\n",
    "    tools=[search_web_tool],\n",
    "    model_client=model_client,\n",
    "    system_message=\"\"\"\n",
    "    You are a web search agent.\n",
    "    Your only tool is search_tool - use it to find information.\n",
    "    You make only one search call at a time.\n",
    "    Once you have the results, you never do calculations based on them.\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "data_analyst_agent = AssistantAgent(\n",
    "    \"DataAnalystAgent\",\n",
    "    description=\"An agent for performing calculations.\",\n",
    "    model_client=model_client,\n",
    "    tools=[percentage_change_tool],\n",
    "    system_message=\"\"\"\n",
    "    You are a data analyst.\n",
    "    Given the tasks you have been assigned, you should analyze the data and provide results using the tools provided.\n",
    "    If you have not seen the data, ask for it.\n",
    "    \"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9168eb1",
   "metadata": {},
   "source": [
    "## Terminate condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce58721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_mention_termination = TextMentionTermination(\"TERMINATE\")\n",
    "max_messages_termination = MaxMessageTermination(max_messages=25)\n",
    "termination = text_mention_termination | max_messages_termination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db769f4",
   "metadata": {},
   "source": [
    "## Selector agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f4f5ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_prompt = \"\"\"Select an agent to perform task.\n",
    "\n",
    "{roles}\n",
    "\n",
    "Current conversation context:\n",
    "{history}\n",
    "\n",
    "Read the above conversation, then select an agent from {participants} to perform the next task.\n",
    "Make sure the planner agent has assigned tasks before other agents start working.\n",
    "Only select one agent.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eed62e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "team = SelectorGroupChat(\n",
    "    [planning_agent, web_search_agent, data_analyst_agent],\n",
    "    model_client=model_client,\n",
    "    termination_condition=termination,\n",
    "    selector_prompt=selector_prompt,\n",
    "    # Allow an agent to speak multiple turns in a row.\n",
    "    allow_repeated_speaker=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6a654d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"Who was the Miami Heat player with the highest points in the 2006-2007 season, and what was the percentage change in his total rebounds between the 2007-2008 and 2008-2009 seasons?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e5a505a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "Who was the Miami Heat player with the highest points in the 2006-2007 season, and what was the percentage change in his total rebounds between the 2007-2008 and 2008-2009 seasons?\n",
      "---------- ToolCallRequestEvent (DataAnalystAgent) ----------\n",
      "[FunctionCall(id='230846901', arguments='{\"season\":\"2006-07\",\"player\":\"Miami Heat\"}', name='get_player_stats')]\n",
      "---------- ToolCallExecutionEvent (DataAnalystAgent) ----------\n",
      "[FunctionExecutionResult(content='Tool get_player_stats not found.', name='get_player_stats', call_id='230846901', is_error=True)]\n",
      "---------- ToolCallSummaryMessage (DataAnalystAgent) ----------\n",
      "Tool get_player_stats not found.\n",
      "---------- TextMessage (PlanningAgent) ----------\n",
      "1. WebSearchAgent : Search for information about Miami Heat players' statistics\n",
      "    2. DataAnalystAgent : Extract the player's name, points average, and total rebounds from the search results\n",
      "    3. DataAnalystAgent : Calculate the percentage change in his total rebounds between the 2007-2008 and 2008-2009 seasons\n",
      "---------- TextMessage (PlanningAgent) ----------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model failed to select a speaker after 3, using the previous speaker.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (PlanningAgent) ----------\n",
      "\n",
      "\n",
      "TERMINATE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, metadata={}, content='Who was the Miami Heat player with the highest points in the 2006-2007 season, and what was the percentage change in his total rebounds between the 2007-2008 and 2008-2009 seasons?', type='TextMessage'), ToolCallRequestEvent(source='DataAnalystAgent', models_usage=RequestUsage(prompt_tokens=477, completion_tokens=38), metadata={}, content=[FunctionCall(id='230846901', arguments='{\"season\":\"2006-07\",\"player\":\"Miami Heat\"}', name='get_player_stats')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='DataAnalystAgent', models_usage=None, metadata={}, content=[FunctionExecutionResult(content='Tool get_player_stats not found.', name='get_player_stats', call_id='230846901', is_error=True)], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='DataAnalystAgent', models_usage=None, metadata={}, content='Tool get_player_stats not found.', type='ToolCallSummaryMessage'), TextMessage(source='PlanningAgent', models_usage=RequestUsage(prompt_tokens=168, completion_tokens=75), metadata={}, content=\"1. WebSearchAgent : Search for information about Miami Heat players' statistics\\n    2. DataAnalystAgent : Extract the player's name, points average, and total rebounds from the search results\\n    3. DataAnalystAgent : Calculate the percentage change in his total rebounds between the 2007-2008 and 2008-2009 seasons\", type='TextMessage'), TextMessage(source='PlanningAgent', models_usage=RequestUsage(prompt_tokens=243, completion_tokens=0), metadata={}, content='', type='TextMessage'), TextMessage(source='PlanningAgent', models_usage=RequestUsage(prompt_tokens=243, completion_tokens=4), metadata={}, content='\\n\\nTERMINATE', type='TextMessage')], stop_reason=\"Text 'TERMINATE' mentioned\")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await Console(team.run_stream(task=task))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs_Agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
